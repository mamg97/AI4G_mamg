{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SCRAP INE Y CORREOS\n",
        "\n",
        "En este notebook se desarrolla un código para la obtención de información masiva de las webs públicas de INE y CORREOS.\n",
        "\n",
        "Para poder utilizarse deben cambiarse las rutas de entrada y salida de datos, así como hacer una revisión de los códigos HTML de los elementos de las webs debido a su naturaleza dinámica (puede cambiar de un día para otro el identificador de cualquiera de los elementos)\n",
        "\n",
        "Se compone de varias partes:\n",
        "\n",
        "1. Tratamiendo inicial de datos para el scraping posterior.\n",
        "2. Scraping del código INE de una serie de poblaciones.\n",
        "3. Scraping del código postal de una serie de poblaciones.\n",
        "4. Post procesado. Aquí se relacionan los códigos INE con los CP de las poblaciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LIBRERÍAS NECESARIAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy\n",
        "import pandas as pd\n",
        "import unicodedata\n",
        "import re\n",
        "import os\n",
        "from datetime import datetime\n",
        "from selenium import webdriver\n",
        "import time\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "import json\n",
        "from fuzzywuzzy import process\n",
        "from fuzzywuzzy import fuzz\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TRATAMIENTO INICIAL DE DATOS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_unidades_poblacionales=pd.read_excel('ruta_1/DATOS POBLACIONES/DATOS_MUNICIPIOS.xlsx',sheet_name='Hoja5',dtype=str)\n",
        "df_datos_municipios=pd.read_excel('ruta_1/POBLACION_INE_CP.xlsx',sheet_name='Hoja1')\n",
        "df_errores=pd.read_excel('ruta_1/POBLACION_INE_CP.xlsx',sheet_name='Hoja2')\n",
        "df_entidades=pd.read_excel('ruta_1/ENTIDADES.xlsx',sheet_name='Hoja1')\n",
        "df_cp=pd.read_excel('ruta_1/DATOS POBLACIONES/ENTIDADES.xlsx',sheet_name='CP',dtype=str)\n",
        "\n",
        "# Eliminar la primera columna y establecer la primera fila como los títulos de las columnas en df1\n",
        "df_unidades_poblacionales = df_unidades_poblacionales.drop(df_unidades_poblacionales.columns[3], axis=1)\n",
        "df_unidades_poblacionales = df_unidades_poblacionales.drop(df_unidades_poblacionales.columns[0], axis=1)\n",
        "df_unidades_poblacionales = df_unidades_poblacionales.rename(columns=df_unidades_poblacionales.iloc[0])\n",
        "df_unidades_poblacionales = df_unidades_poblacionales.drop(df_unidades_poblacionales.index[0])\n",
        "\n",
        "# Eliminar la primera columna y establecer la primera fila como los títulos de las columnas en df2\n",
        "df_datos_municipios = df_datos_municipios.drop(df_datos_municipios.columns[0], axis=1)\n",
        "df_datos_municipios = df_datos_municipios.rename(columns=df_datos_municipios.iloc[0])\n",
        "df_datos_municipios = df_datos_municipios.drop(df_datos_municipios.index[0])\n",
        "\n",
        "# Definir función para quitar tildes y poner en minúscula\n",
        "def quitar_tildes(texto):\n",
        "    texto_sin_tildes = ''.join((c for c in unicodedata.normalize('NFD', texto) if unicodedata.category(c) != 'Mn'))\n",
        "    return texto_sin_tildes.lower()\n",
        "\n",
        "# Aplicar la función a las columnas \"PROVINCIA\" y \"POBLACIÓN\" del DataFrame\n",
        "df_datos_municipios[\"PROVINCIA\"] = df_datos_municipios[\"PROVINCIA\"].apply(quitar_tildes)\n",
        "df_datos_municipios[\"POBLACIÓN\"] = df_datos_municipios[\"POBLACIÓN\"].apply(quitar_tildes)\n",
        "df_unidades_poblacionales[\"CITY1\"]=df_unidades_poblacionales[\"CITY1\"].apply(quitar_tildes)\n",
        "\n",
        "df_entidades['_CODIGOINE'] = df_entidades['_CODIGOINE'].str.replace('_', '').astype(str)\n",
        "# df_entidades = df_entidades.drop(['COD_PROV', 'PROVINCIA', 'TIPO', 'POBLACION', 'INEMUNI', 'HOJA_MTN25', 'LONGITUD_ETRS89', 'LATITUD_ETRS89', 'ORIGENCOOR', 'ALTITUD', 'ORIGENALTITUD', 'SUPRIMIDA_INE', 'DISCREPANTE_INE'], axis=1)\n",
        "df_entidades = df_entidades.drop([ 'CODIGOINE'], axis=1)\n",
        "df_entidades[\"NOMBRE\"]=df_entidades[\"NOMBRE\"].apply(quitar_tildes)\n",
        "df_entidades['_CODIGOINE'] = df_entidades['_CODIGOINE'].str.slice(stop=5)\n",
        "df_entidades = df_entidades.drop_duplicates(subset=['NOMBRE', '_CODIGOINE'])\n",
        "\n",
        "df_entidades.to_excel('ruta_1/entidades_depuradas.xlsx')\n",
        "\n",
        "df_errores = df_errores.drop(df_errores.columns[0], axis=1)\n",
        "df_errores = df_errores.drop(df_errores.columns[0], axis=1)\n",
        "df_errores = df_errores.rename(columns=df_errores.iloc[0])\n",
        "df_errores = df_errores.drop(df_errores.index[0])\n",
        "df_errores = df_errores.astype(str)\n",
        "\n",
        "df_errores['POBLACIÓN / UD POBLACIONAL']=df_errores['POBLACIÓN / UD POBLACIONAL'].apply(quitar_tildes)\n",
        "df_errores.drop_duplicates(inplace=True)\n",
        "\n",
        "df_errores['CLAVE']=df_errores['POBLACIÓN / UD POBLACIONAL']+'_'+df_errores['INE_CP']\n",
        "\n",
        "df_errores.drop_duplicates(subset=['CLAVE'], inplace=True)\n",
        "\n",
        "df_errores.to_excel('ruta_1/SOL_ERRORES_POB.xlsx')\n",
        "\n",
        "df_unidades_poblacionales.to_excel('ruta_1/referencia_NORMALIZADO.xlsx')\n",
        "\n",
        "df_cp=df_cp.drop(['NOMBRE_COMUNIDAD', 'COD_PROVINCIA', 'COD_MUNICIPIO'],axis=1)\n",
        "df_cp[\"NOMBRE_POBLACION\"]=df_cp[\"NOMBRE_POBLACION\"].apply(quitar_tildes)\n",
        "df_cp[\"NOMBRE_MUNICIPIO\"]=df_cp[\"NOMBRE_MUNICIPIO\"].apply(quitar_tildes)\n",
        "df_cp.to_excel('ruta_1/CP_depurados.xlsx')\n",
        "\n",
        "# eliminamos los espacios adicionales al final de las cadenas en las columnas 'NOMBRE_POBLACION'\n",
        "df_cp['NOMBRE_POBLACION'] = df_cp['NOMBRE_POBLACION'].str.strip()\n",
        "df_entidades['NOMBRE_POBLACION'] = df_entidades['NOMBRE_POBLACION'].str.strip()\n",
        "\n",
        "# renombramos la columna 'NOMBRE' a 'NOMBRE_POBLACION' en el dataframe df_entidades\n",
        "df_entidades = df_entidades.rename(columns={'NOMBRE': 'NOMBRE_POBLACION'})\n",
        "\n",
        "# realizamos el OUTER JOIN por la columna común 'NOMBRE_POBLACION'\n",
        "df_resultado = df_cp.merge(df_entidades, how='outer', on='NOMBRE_POBLACION')\n",
        "df_resultado3 = df_cp.merge(df_entidades, how='inner', on='NOMBRE_POBLACION')\n",
        "\n",
        "df_resultado1 = df_cp.merge(df_entidades, how='outer', left_on='NOMBRE_POBLACION', right_on='NOMBRE')\n",
        "df_resultado2= df_cp.merge(df_entidades, how='outer', left_on='NOMBRE_MUNICIPIO', right_on='NOMBRE')\n",
        "\n",
        "df_entidades = df_entidades.rename(columns={'NOMBRE_POBLACION': 'NOMBRE_MUNICIPIO'})\n",
        "df_resultado4=df_cp.merge(df_entidades, how='inner', on='NOMBRE_MUNICIPIO')\n",
        "\n",
        "df_resultado1.to_excel('ruta_1/res1.xlsx')\n",
        "df_resultado2.to_excel('ruta_1/res2.xlsx')\n",
        "\n",
        "# concatenamos los dataframes df_resultado3 y df_resultado4\n",
        "df_concatenado = pd.concat([df_resultado3, df_resultado4], ignore_index=True)\n",
        "\n",
        "df_concatenado.to_excel('ruta_1/concatenado.xlsx')\n",
        "\n",
        "df_unidades_poblacionales=df_unidades_poblacionales.rename(columns={'CITY1': 'NOMBRE_MUNICIPIO'})\n",
        "\n",
        "referencia1 = pd.merge(df_unidades_poblacionales,df_concatenado, how='left', on='NOMBRE_MUNICIPIO')\n",
        "\n",
        "df_unidades_poblacionales=df_unidades_poblacionales.rename(columns={'NOMBRE_MUNICIPIO': 'NOMBRE_POBLACION'})\n",
        "\n",
        "referencia2 = pd.merge(df_unidades_poblacionales,df_concatenado, how='left', on='NOMBRE_POBLACION')\n",
        "\n",
        "df_concatenado2=pd.concat([referencia1, referencia2], ignore_index=True)\n",
        "\n",
        "df_concatenado3=pd.concat([df_concatenado, df_concatenado2], ignore_index=True)\n",
        "\n",
        "df_concatenado3['POST_CODE1'] = df_concatenado3['POST_CODE1'].str.zfill(5)\n",
        "\n",
        "df_concatenado3.to_excel('ruta_1/final.xlsx')\n",
        "\n",
        "df_entidades.reset_index()\n",
        "df_cp.reset_index()\n",
        "posicion_cp = df_cp.loc[df_cp['NOMBRE_POBLACION'] == 'la albuera'].index[0]\n",
        "posicion_entidades = df_entidades.loc[df_entidades['NOMBRE_POBLACION'] == 'la albuera'].index[0]\n",
        "\n",
        "# comparamos las posiciones\n",
        "if posicion_cp == posicion_entidades:\n",
        "    print(\"La posición de 'la albuera' es la misma en ambos dataframes: \", posicion_cp)\n",
        "else:\n",
        "    print(\"Las posiciones de 'la albuera' son diferentes en cada dataframe.\")\n",
        "    print(\"Posición en df_cp: \", posicion_cp)\n",
        "    print(\"Posición en df_entidades: \", posicion_entidades)\n",
        "\n",
        "\n",
        "# extraemos la fila 3393 del dataframe df_cp\n",
        "fila_3393 = df_cp.iloc[3392]\n",
        "\n",
        "# mostramos la fila extraída\n",
        "print(fila_3393)\n",
        "\n",
        "valor_cp = df_cp.iloc[posicion_cp]['NOMBRE_POBLACION']\n",
        "valor_entidades = df_entidades.iloc[posicion_entidades]['NOMBRE_POBLACION']\n",
        "\n",
        "# comparamos los valores\n",
        "if valor_cp == valor_entidades:\n",
        "    print(\"El valor de NOMBRE_POBLACION es el mismo en ambas posiciones: \", valor_cp)\n",
        "else:\n",
        "    print(\"Los valores de NOMBRE_POBLACION son diferentes en cada posición.\")\n",
        "    print(\"Valor de NOMBRE_POBLACION en la posición \", posicion_cp, \" en df_cp: \", valor_cp)\n",
        "    print(\"Valor de NOMBRE_POBLACION en la posición \", posicion_entidades, \" en df_entidades: \", valor_entidades)\n",
        "\n",
        "\n",
        "#LEFT JOIN A LOS CP DE referencia PARA SACAR\n",
        "\n",
        "df_cp['C.POSTAL'] = df_cp['C.POSTAL'].astype(str).str.zfill(5)\n",
        "\n",
        "df_cp['COD_PROVINCIA'] = df_cp['COD_PROVINCIA'].astype(str).str.zfill(2)\n",
        "df_cp['COD_MUNICIPIO'] = df_cp['COD_MUNICIPIO'].astype(str).str.zfill(4)\n",
        "\n",
        "df_cp['COD_INE']=df_cp['COD_PROVINCIA']+df_cp['COD_MUNICIPIO']\n",
        "\n",
        "df_cp = df_cp.rename(columns={'C.POSTAL': 'CP'})\n",
        "df_unidades_poblacionales=df_unidades_poblacionales.rename(columns={'POST_CODE1': 'CP'})\n",
        "\n",
        "CP_INE_referencia = pd.merge(df_unidades_poblacionales,df_cp, how='left', on='CP')\n",
        "\n",
        "# Agrupa los datos por el valor de CP y concatena los valores de COD_INE separados por una coma\n",
        "CP_INE_referencia_2=CP_INE_referencia.copy()\n",
        "\n",
        "# Agrupa los datos por \"CP\" y crea una nueva Serie de pandas con todos los valores de \"COD_INE\" para cada grupo, eliminando los valores duplicados\n",
        "cod_ine_por_cp = CP_INE_referencia_2.groupby('CP')['COD_INE'].apply(lambda x: ','.join(pd.unique(x).astype(str))).reset_index(name='COD_INE para cada CP')\n",
        "\n",
        "# Combina la nueva columna con el DataFrame original\n",
        "df_con_cod_ine = pd.merge(CP_INE_referencia_2, cod_ine_por_cp, on='CP')\n",
        "\n",
        "# Elimina las filas duplicadas\n",
        "df_con_cod_ine_sin_duplicados = df_con_cod_ine.drop_duplicates()\n",
        "\n",
        "\n",
        "df_con_cod_ine.to_excel('ruta_1/df_con_cod_ine.xlsx')\n",
        "\n",
        "df_datos_referencia=pd.read_excel('ruta_1/DATOS_INE.xlsx',sheet_name='Hoja4',dtype=str)\n",
        "df_datos_ine=pd.read_excel('ruta_1/DATOS_INE.xlsx',sheet_name='Hoja2',dtype=str)\n",
        "\n",
        "# Eliminar la primera columna y establecer la primera fila como los títulos de las columnas en datos_referencia\n",
        "df_datos_referencia = df_datos_referencia.drop(df_datos_referencia.columns[0], axis=1)\n",
        "df_datos_referencia = df_datos_referencia.rename(columns=df_datos_referencia.iloc[1])\n",
        "df_datos_referencia = df_datos_referencia.drop(df_datos_referencia.index[0])\n",
        "\n",
        "df_datos_ine = df_datos_ine.drop(df_datos_ine.columns[3], axis=1)\n",
        "df_datos_ine = df_datos_ine.drop(df_datos_ine.columns[2], axis=1)\n",
        "df_datos_ine = df_datos_ine.drop(df_datos_ine.columns[1], axis=1)\n",
        "df_datos_ine = df_datos_ine.drop(df_datos_ine.columns[0], axis=1)\n",
        "\n",
        "copia_referencia=df_datos_referencia.copy()\n",
        "copia_datos_ine=df_datos_ine.copy()\n",
        "\n",
        "# función para aplicar a cada valor de la columna CITY1\n",
        "def transform_city(city):\n",
        "    # expresión regular para buscar los artículos en el nombre de ciudad\n",
        "    pattern = r'^(EL|LA|LOS|LAS)\\s'\n",
        "    # buscar el patrón en el nombre de ciudad\n",
        "    match = re.search(pattern, city)\n",
        "    if match:\n",
        "        # si se encuentra el patrón, reemplazar el artículo con el artículo entre paréntesis\n",
        "        article = match.group(1)\n",
        "        city = re.sub(pattern, '', city)\n",
        "        city = f'{city} ({article})'\n",
        "    return city\n",
        "\n",
        "# aplicar la función a la columna CITY1\n",
        "df_datos_referencia['CITY1'] = df_datos_referencia['CITY1'].apply(lambda x: transform_city(x))\n",
        "\n",
        "\n",
        "# función para aplicar a cada valor de la columna CITY1\n",
        "def transform_city2(city):\n",
        "    # expresión regular para buscar el artículo al final del nombre de ciudad después de una coma\n",
        "    pattern_end = r',\\s*(EL|LA|LOS|LAS)$'\n",
        "    \n",
        "    # buscar el patrón de artículo al final del nombre de ciudad después de una coma\n",
        "    match_end = re.search(pattern_end, city)\n",
        "    if match_end:\n",
        "        # si se encuentra el patrón, reemplazar el artículo con el artículo entre paréntesis\n",
        "        article = match_end.group(1)\n",
        "        city = re.sub(pattern_end, '', city)\n",
        "        city = f'{city} ({article})'\n",
        "        return city\n",
        "    \n",
        "    # si no se encuentra ningún patrón, devolver el nombre de ciudad sin cambios\n",
        "    return city\n",
        "\n",
        "# aplicar la función a la columna CITY1\n",
        "df_datos_referencia['CITY1'] = df_datos_referencia['CITY1'].apply(lambda x: transform_city2(x))\n",
        "\n",
        "df_datos_referencia = df_datos_referencia.drop_duplicates(subset=['POST_CODE1', 'CITY1'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SCRAPING_INE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# IMPORTACIÓN DEL EXCEL CON LOS DATOS DE CP POBLACIÓN Y COD INE\n",
        "\n",
        "df_datos=pd.read_excel('ruta_1/CP_INE/CP_INE_py_faltan_9_20.xlsx',sheet_name='Hoja1',dtype=str)\n",
        "print(\"Datos importados\")\n",
        "def find_longest_word(text):\n",
        "    words = text.split()\n",
        "    longest_word = max(words, key=len)\n",
        "    return longest_word\n",
        "\n",
        "df_datos['POBLACION'] = df_datos['CITY1'].apply(find_longest_word)\n",
        "df_datos['POBLACION'] = df_datos['POBLACION'].str.replace(\"-\", \"\")\n",
        "df_datos['POBLACION'] = df_datos['POBLACION'].str.replace(\",\", \"\")\n",
        "\n",
        "# CONEXIÓN A LA WEB DEL INE Y COMIENZO DEL BUCLE DE INTRODUCCIÓN DE CÓDIGOS Y OBTENCIÓN DE TABLAS\n",
        "\n",
        "# driver = webdriver.Chrome(\"ruta_2/chromedriver_win32/chromedriver.exe\")\n",
        "driver = webdriver.Chrome()\n",
        "driver.get('https://www.ine.es/nomen2/index.do')\n",
        "driver.maximize_window() #Maximizo la pantalla\n",
        "time.sleep(2)\n",
        "print(\"Conectado con el INE\")\n",
        "# Hacer clic en el botón de aceptar cookies\n",
        "aceptar_cookies = driver.find_element('id','aceptarCookie')\n",
        "aceptar_cookies.click()\n",
        "\n",
        "datos = []\n",
        "print(\"Datos cargados\")\n",
        "i=1\n",
        "for index, row in df_datos.iterrows():\n",
        "    # Obtener el nombre clave de la población\n",
        "    # index=0\n",
        "    name = row['POBLACION']\n",
        "    print(name)\n",
        "    \n",
        "    porc_completo=(i/len(df_datos))*100\n",
        "    i=i+1\n",
        "    print(f'Completado al {porc_completo} %')\n",
        "    \n",
        "    # Introducir el código de provincia y el código de municipio en los campos correspondientes\n",
        "    campo_nombre = driver.find_element('id',\"nombrePoblacion\")\n",
        "    campo_nombre.clear()#Limpio el campo donde introduzco la referencia\n",
        "    campo_nombre.send_keys(name)\n",
        "\n",
        "    # time.sleep(2)\n",
        "    # Pulsar la tecla ENTER para enviar los datos\n",
        "    campo_nombre.send_keys(Keys.ENTER) #Pulso intro en el campo\n",
        "    \n",
        "    # Datos tabla\n",
        "    try:                    \n",
        "            # Esperar a que la tabla cargue\n",
        "            WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"datos\")))\n",
        "            \n",
        "            # Obtener la tabla\n",
        "            tabla = driver.find_element(By.CLASS_NAME, \"datos\")\n",
        "            \n",
        "            # Obtener la cabecera de la tabla\n",
        "            cabecera = tabla.find_element(By.CLASS_NAME, \"cabtab\")\n",
        "            \n",
        "            # Obtener los nombres de las columnas de la tabla\n",
        "            provincia = driver.find_element('id', \"p\").text\n",
        "            municipio = driver.find_element('id', \"m\").text\n",
        "            unidad_poblacional = driver.find_element('id', \"u\").text\n",
        "            \n",
        "            # Obtener los datos de la tabla\n",
        "            cuerpo = tabla.find_element(By.TAG_NAME, \"tbody\")\n",
        "            filas = cuerpo.find_elements(By.TAG_NAME, \"tr\")\n",
        "            \n",
        "            # Iterar por las filas de la tabla\n",
        "            for fila in filas[2:]:\n",
        "                # print(fila)\n",
        "                # Encontrar los elementos th y td de la fila\n",
        "                ths = fila.find_elements(By.TAG_NAME,'th')\n",
        "                # print(ths)\n",
        "                # tds = fila.find_elements_by_tag_name('td')\n",
        "                \n",
        "                # Extraer el texto de los elementos th y td y almacenarlo en variables\n",
        "                codigo_provincia = ths[0].text.split()[0] # Código de provincia\n",
        "                provincia = ' '.join(ths[0].text.split()[1:]) # Nombre de la provincia\n",
        "                codigo_municipio = ths[1].text.split()[0] # Código de municipio\n",
        "                municipio = ' '.join(ths[1].text.split()[1:]) # Nombre del municipio\n",
        "                codigo_up = ths[2].text.split()[0] # Código de unidad poblacional\n",
        "                up = ' '.join(ths[2].text.split()[1:]) # Nombre de la unidad poblacional\n",
        "                \n",
        "                # Imprimir los valores\n",
        "                # print(codigo_provincia, provincia, codigo_municipio, municipio, codigo_up, up)#, poblacion_total.text, hombres.text, mujeres.text)\n",
        "                datos.append({\n",
        "                              'Cod provincia':codigo_provincia,\n",
        "                              'Provincia': provincia, \n",
        "                              'Cod municipio': codigo_municipio,\n",
        "                              'Municipio': municipio, \n",
        "                              'Codigo ud pob': codigo_up,\n",
        "                              'Ud pob': up})\n",
        "    except:\n",
        "        # En caso de que no se encuentre la tabla, añadir una fila con valores nulos\n",
        "                datos.append({\n",
        "                              'Cod provincia':None,\n",
        "                              'Provincia': None, \n",
        "                              'Cod municipio': None,\n",
        "                              'Municipio': None, \n",
        "                              'Codigo ud pob': None,\n",
        "                              'Ud pob': None})\n",
        "    driver.get('https://www.ine.es/nomen2/index.do ')\n",
        "# Cerrar el driver\n",
        "driver.quit()\n",
        "\n",
        "# Convertir la lista de datos en un dataframe\n",
        "df_resultado = pd.DataFrame(datos)\n",
        "\n",
        "# Imprimir el resultado\n",
        "print(df_resultado)\n",
        "\n",
        "# EXPORTACIÓN DE RESULTADOS\n",
        "df_resultado.to_excel('ruta_1/CP_INE/datos_ine_nuevos_2.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SCRAPING_CORREOS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# IMPORTACIÓN DEL EXCEL CON LOS DATOS DE CP POBLACIÓN Y COD INE\n",
        " \n",
        "df_datos_7=pd.read_excel('ruta_1/BASE DATOS INE CP DEFINITIVO_AUX.xlsx',sheet_name='FALTAN CORREOS',dtype=str)\n",
        "print(\"Datos importados\")\n",
        " \n",
        "# CONEXIÓN A LA WEB DEL INE Y COMIENZO DEL BUCLE DE INTRODUCCIÓN DE CÓDIGOS Y OBTENCIÓN DE TABLAS\n",
        " \n",
        "driver = webdriver.Chrome(executable_path=r\"ruta_2\\chromedriver_win32\\chromedriver.exe\")\n",
        "driver.get('https://www.correos.es/es/es/herramientas/codigos-postales/detalle')\n",
        "driver.maximize_window() #Maximizo la pantalla\n",
        "time.sleep(2)\n",
        "print(\"Conectado con el Correos\")\n",
        "# Hacer clic en el botón de aceptar cookies\n",
        "x_path_aceptar_cookies = \"//button[contains(@class,'sc-correos-ui-button') and contains(@aria-label,'Aceptar todas las cookies')]\"\n",
        "# Esperar hasta que el botón esté visible\n",
        "aceptar_cookies = WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, x_path_aceptar_cookies)))\n",
        "# Hacer clic en el botón\n",
        "aceptar_cookies.click()\n",
        "\n",
        "# Crear dataframe general vacío\n",
        "df_general = pd.DataFrame()\n",
        "\n",
        "print(\"Datos cargados\")\n",
        "i=1\n",
        "\n",
        "for index, row in df_datos_7.iterrows():\n",
        "    # Obtener el código de provincia y el código de municipio de la fila actual\n",
        "    index=0\n",
        "    cp = row['CP']\n",
        "    print(cp)\n",
        "    i=i+1\n",
        "    porc_completo=(i/len(df_datos_7))*100\n",
        "    print(f'Completado al {porc_completo} %')\n",
        "    \n",
        "    # Introducir el código de provincia y el código de municipio en los campos correspondientes\n",
        "    campo_cp = driver.find_element(By.CSS_SELECTOR,\"input[id*='correos-ui-input']\")\n",
        "    campo_cp.clear()#Limpio el campo donde introduzco la referencia\n",
        "    campo_cp.send_keys(cp)\n",
        "    \n",
        "    # Pulsar la tecla ENTER para enviar los datos\n",
        "    campo_cp.send_keys(Keys.ENTER) #Pulso intro en el campo\n",
        "\n",
        "    # Datos tabla\n",
        "    try:                 \n",
        "            # Esperar a que se muestren los resultados de la búsqueda\n",
        "            elemento_resultados = WebDriverWait(driver, 30).until(EC.visibility_of_element_located((By.CSS_SELECTOR, '.sc-correos-ui-list-cp-results-h')))\n",
        "            \n",
        "            # Obtener la cadena que contiene los datos\n",
        "            literals = driver.find_element(By.CSS_SELECTOR,'.sc-correos-ui-list-cp-results-h').get_attribute('literals')\n",
        "            # Convertir la cadena a un objeto JSON\n",
        "            literals_json = json.loads(literals.replace('&quot;', '\"'))\n",
        "            \n",
        "            postal_codes = []\n",
        "            provincias = []\n",
        "            localidades = []\n",
        "            \n",
        "            # Iterar sobre la lista de literales y extraer los datos necesarios\n",
        "            for literal in literals_json:\n",
        "                postalCodeNumber = literal['postalCodeNumber']\n",
        "                provincia = literal['listDescription'][0]['definition']\n",
        "                localidad = literal['listDescription'][1]['definition']\n",
        "                \n",
        "                postal_codes.append(postalCodeNumber)\n",
        "                provincias.append(provincia)\n",
        "                localidades.append(localidad)\n",
        "            df = pd.DataFrame({'postal_code': postal_codes, 'provincia': provincias, 'localidad': localidades})\n",
        "    except:\n",
        "        # Si no se encuentra la tabla, crear un dataframe con valores nulos\n",
        "        df = pd.DataFrame({'postal_code': [None], 'provincia': [None], 'localidad': [None]})\n",
        "        print(f'Error en {cp}')\n",
        "    \n",
        "    # Añadir el dataframe al dataframe general\n",
        "    df_general = pd.concat([df_general, df], ignore_index=True)\n",
        "\n",
        "# Cerrar el driver\n",
        "driver.quit()\n",
        "\n",
        "# Imprimir el resultado\n",
        "print(df_general)\n",
        "\n",
        "df_general.to_excel('ruta_1/correos_7.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## POST PROCESADO\n",
        "\n",
        "Una vez se tienen los datos masivos descargados se procesan para buscar la correspondencia del código INE de cada población con el código postal extraído de la web de correos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "faltan = pd.read_excel('ruta_1/CP_INE/CIS_2021_20230407.XLSX',\n",
        "                       sheet_name='Faltan',\n",
        "                       dtype={'POST_CODE1': str, 'CITY1': str})\n",
        "\n",
        "base_ine = pd.read_excel('ruta_1/CP_INE/CIS_2021_20230407.XLSX',\n",
        "                         sheet_name='BASE DATOS INE',\n",
        "                         dtype={'COD_INE': str, 'Ud pob': str})\n",
        "\n",
        "# Supongamos que tus dataframes se llaman df1 y df2\n",
        "df1 = faltan\n",
        "df2 = base_ine\n",
        "\n",
        "# Vamos a convertir los valores de las columnas POST_CODE y COD_INE a string\n",
        "df1['POST_CODE1'] = df1['POST_CODE1'].astype(str)\n",
        "df2['COD_INE'] = df2['COD_INE'].astype(str)\n",
        "\n",
        "# Creamos una función para buscar la coincidencia de los dos primeros dígitos y un 80% de similitud en las ciudades\n",
        "def find_cod_ine(row):\n",
        "    post_code = row['POST_CODE1']\n",
        "    city1 = row['CITY1']\n",
        "    \n",
        "    # Filtramos el df2 por los dos primeros dígitos\n",
        "    df2_filtered = df2[df2['COD_INE'].str.startswith(post_code[:2])]\n",
        "    \n",
        "    # Si no hay coincidencias en los dos primeros dígitos, retornamos NaN\n",
        "    if df2_filtered.empty:\n",
        "        return float('nan')\n",
        "    \n",
        "    for index, row in df2_filtered.iterrows():\n",
        "        if fuzz.ratio(city1.lower(), row['Ud pob'].lower()) >= 100:\n",
        "            return row['COD_INE'], row['Ud pob']\n",
        "\n",
        "    return float('nan'), float('nan')\n",
        "\n",
        "# Aplicamos la función a cada fila de df1\n",
        "df1[['COD_INE_MATCH', 'UD_POB_MATCH']] = df1.apply(\n",
        "    lambda row: pd.Series(find_cod_ine(row)), axis=1)\n",
        "\n",
        "df1_terminado=df1.loc[df1['COD_INE_MATCH'].notna()]\n",
        "df1=df1[df1['COD_INE_MATCH'].isna()]\n",
        "\n",
        "len(df1)\n",
        "df1_terminado.to_excel('ruta_1/CP_INE/CP_INE_py_2.xlsx')\n",
        "\n",
        "# Creamos una función para buscar la coincidencia de los dos primeros dígitos y un 80% de similitud en las ciudades\n",
        "def find_cod_ine(row):\n",
        "    post_code = row['POST_CODE1']\n",
        "    city1 = row['CITY1']\n",
        "    \n",
        "    # Filtramos el df2 por los dos primeros dígitos\n",
        "    df2_filtered = df2[df2['COD_INE'].str.startswith(post_code[:2])]\n",
        "    \n",
        "    # Si no hay coincidencias en los dos primeros dígitos, retornamos NaN\n",
        "    if df2_filtered.empty:\n",
        "        return float('nan')\n",
        "    \n",
        "    for index, row in df2_filtered.iterrows():\n",
        "        if fuzz.ratio(city1.lower(), row['Ud pob'].lower()) >= 90:\n",
        "            return row['COD_INE'], row['Ud pob']\n",
        "\n",
        "    return float('nan'), float('nan')\n",
        "\n",
        "# Aplicamos la función a cada fila de df1\n",
        "df1[['COD_INE_MATCH', 'UD_POB_MATCH']] = df1.apply(\n",
        "    lambda row: pd.Series(find_cod_ine(row)), axis=1)\n",
        "\n",
        "df1_terminado2=df1.loc[df1['COD_INE_MATCH'].notna()]\n",
        "df1=df1[df1['COD_INE_MATCH'].isna()]\n",
        "\n",
        "len(df1)\n",
        "df1_terminado2.to_excel('ruta_1/CP_INE/CP_INE_py_3.xlsx')\n",
        "\n",
        "df1.to_excel('ruta_1/CP_INE/CP_INE_py_faltan_9_20.xlsx')\n",
        "\n",
        "# Creamos una función para buscar la coincidencia de los dos primeros dígitos y un 80% de similitud en las ciudades\n",
        "def find_cod_ine(row):\n",
        "    post_code = row['POST_CODE1']\n",
        "    city1 = row['CITY1']\n",
        "    \n",
        "    # Filtramos el df2 por los dos primeros dígitos\n",
        "    df2_filtered = df2[df2['COD_INE'].str.startswith(post_code[:2])]\n",
        "    \n",
        "    # Si no hay coincidencias en los dos primeros dígitos, retornamos NaN\n",
        "    if df2_filtered.empty:\n",
        "        return float('nan')\n",
        "    \n",
        "    for index, row in df2_filtered.iterrows():\n",
        "        if fuzz.ratio(city1.lower(), row['Ud pob'].lower()) >= 80:\n",
        "            return row['COD_INE'], row['Ud pob']\n",
        "\n",
        "    return float('nan'), float('nan')\n",
        "\n",
        "# Aplicamos la función a cada fila de df1\n",
        "df1[['COD_INE_MATCH', 'UD_POB_MATCH']] = df1.apply(\n",
        "    lambda row: pd.Series(find_cod_ine(row)), axis=1)\n",
        "\n",
        "df1_terminado3=df1.loc[df1['COD_INE_MATCH'].notna()]\n",
        "len(df1_terminado3)\n",
        "\n",
        "df1=df1[df1['COD_INE_MATCH'].isna()]\n",
        "len(df1)\n",
        "\n",
        "df1_terminado3.to_excel('ruta_1/CP_INE/CP_INE_py_4.xlsx')\n",
        "\n",
        "faltan = pd.read_excel('ruta_1/CP_INE/CP_INE_py_faltan_9_20.xlsx',\n",
        "                       sheet_name='Sheet1',\n",
        "                       dtype={'POST_CODE1': str, 'CITY1': str})\n",
        "\n",
        "faltan2 = pd.read_excel('ruta_1/CP_INE/CP_INE_py_faltan_9_20.xlsx',\n",
        "                       sheet_name='Hoja1',\n",
        "                       dtype={'POST_CODE1': str, 'CITY1': str})\n",
        "\n",
        "base_ine = pd.read_excel('ruta_1/CP_INE/datos_ine_nuevos_1.xlsx',\n",
        "                         sheet_name='BASE DATOS INE',\n",
        "                         dtype={'COD_INE': str, 'Ud pob': str})\n",
        "\n",
        "# Supongamos que tus dataframes se llaman df1 y df2\n",
        "df1 = faltan\n",
        "df2 = base_ine\n",
        "\n",
        "df1_cop=df1.copy()\n",
        "\n",
        "faltan2['COD_INE_MATCH'] = np.nan\n",
        "faltan2['UD_POB_MATCH'] = np.nan\n",
        "df1 = df1.drop('Unnamed: 0', axis=1)\n",
        "\n",
        "df1 = pd.concat([df1, faltan2], ignore_index=True)\n",
        "\n",
        "# Vamos a convertir los valores de las columnas POST_CODE y COD_INE a string\n",
        "df1['POST_CODE1'] = df1['POST_CODE1'].astype(str)\n",
        "df2['COD_INE'] = df2['COD_INE'].astype(str)\n",
        "\n",
        "# Creamos una función para buscar la coincidencia de los dos primeros dígitos y un 80% de similitud en las ciudades\n",
        "def find_cod_ine(row):\n",
        "    post_code = row['POST_CODE1']\n",
        "    city1 = row['CITY1']\n",
        "    \n",
        "    # Filtramos el df2 por los dos primeros dígitos\n",
        "    df2_filtered = df2[df2['COD_INE'].str.startswith(post_code[:2])]\n",
        "    \n",
        "    # Si no hay coincidencias en los dos primeros dígitos, retornamos NaN\n",
        "    if df2_filtered.empty:\n",
        "        return float('nan')\n",
        "    \n",
        "    for index, row in df2_filtered.iterrows():\n",
        "        if fuzz.ratio(city1.lower(), row['Ud pob'].lower()) >= 80:\n",
        "            return row['COD_INE'], row['Ud pob']\n",
        "\n",
        "    return float('nan'), float('nan')\n",
        "\n",
        "# Aplicamos la función a cada fila de df1\n",
        "df1[['COD_INE_MATCH', 'UD_POB_MATCH']] = df1.apply(\n",
        "    lambda row: pd.Series(find_cod_ine(row)), axis=1)\n",
        "\n",
        "df1_terminado=df1.loc[df1['COD_INE_MATCH'].notna()]\n",
        "df1_terminado2=df1.loc[df1['COD_INE_MATCH'].notna()]\n",
        "df1_terminado3=df1.loc[df1['COD_INE_MATCH'].notna()]\n",
        "df1_terminado4=df1.loc[df1['COD_INE_MATCH'].notna()]\n",
        "\n",
        "df1_terminado5= pd.concat([df1_terminado, df1_terminado2, df1_terminado3, df1_terminado4], ignore_index=True)\n",
        "\n",
        "df1_terminado6=df1\n",
        "\n",
        "df1=df1[df1['COD_INE_MATCH'].isna()]\n",
        "\n",
        "len(df1)\n",
        "df1_terminado6.to_excel('ruta_1/CP_INE/CP_INE_py_6.xlsx')\n",
        "len(df1_terminado)\n",
        "\n",
        "faltan = pd.read_excel('ruta_1/CP_INE/CP_INE_py_6.xlsx',dtype=str)\n",
        "faltan['CITY1_2']=faltan['CITY1']\n",
        "\n",
        "faltan['CITY1_2'] = faltan['CITY1_2'].str.replace(\"-\", \" \")\n",
        "# faltan['CITY1_2'] = faltan['CITY1_2'].str.replace(\",\", \" \")\n",
        "faltan['CITY1_2'] = faltan['CITY1_2'].str.replace(\"(\", \" \")\n",
        "faltan['CITY1_2'] = faltan['CITY1_2'].str.replace(\")\", \" \")\n",
        "\n",
        "def check_city_match(row):\n",
        "    city1 = row['CITY1']\n",
        "    pueblo_base_date = row['pueblo_base_date']\n",
        "\n",
        "    # Comprobamos si alguno de los valores es NaN\n",
        "    if pd.isnull(city1) or pd.isnull(pueblo_base_date):\n",
        "        return 'ERROR'\n",
        "    # Calculamos el porcentaje de coincidencia entre los dos nombres de la ciudad\n",
        "    elif fuzz.ratio(city1.lower(), pueblo_base_date.lower()) >= 50:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Aplicamos la función a cada fila del dataframe\n",
        "faltan['city_match'] = faltan.apply(check_city_match, axis=1)\n",
        "\n",
        "# Creamos un DataFrame solo con las filas donde 'city_match' es 1\n",
        "df_match = faltan.loc[faltan['city_match'] == 1]\n",
        "\n",
        "# Creamos otro DataFrame con las filas restantes\n",
        "df_no_match = faltan.loc[faltan['city_match'] != 1]\n",
        "\n",
        "df_match.to_excel('ruta_1/CP_INE/df_match.xlsx')\n",
        "df_no_match.to_excel('ruta_1/CP_INE/df_NO_match.xlsx')\n",
        "\n",
        "faltan = pd.read_excel('ruta_1/CP_INE/df_NO_match.xlsx',dtype=str)\n",
        "datos_ine = pd.read_excel('ruta_1/CP_INE/CIS_2021_20230407.xlsx',sheet_name=\"BASE DATOS INE\",dtype=str)\n",
        "\n",
        "def match_name(name, list_names, min_score=0):\n",
        "    max_score = -1\n",
        "    max_name = \"\"\n",
        "    for name2 in list_names:\n",
        "        score = fuzz.ratio(name, name2)\n",
        "        if (score > min_score) & (score > max_score):\n",
        "            max_name = name2\n",
        "            max_score = score\n",
        "    return (max_name, max_score)\n",
        "\n",
        "dict_list = []\n",
        "\n",
        "for name in tqdm(faltan['CITY1_2']):\n",
        "    match = match_name(name, datos_ine['Ud pob'], 50)\n",
        "    dict_ = {}\n",
        "    dict_.update({\"CITY1_2\" : name})\n",
        "    dict_.update({\"match_name\" : match[0]})\n",
        "    dict_.update({\"score\" : match[1]})\n",
        "    dict_list.append(dict_)\n",
        "    \n",
        "merge_table = pd.DataFrame(dict_list)\n",
        "print(merge_table)\n",
        "\n",
        "datos_ine_list = datos_ine[['Ud pob', 'COD_INE']].values.tolist()\n",
        "\n",
        "def match_name(row, list_names_codes, min_score=0):\n",
        "    name = row['CITY1_2']\n",
        "    code = row['ine_base_date']\n",
        "    max_score = -1\n",
        "    max_name = \"\"\n",
        "    max_code = \"\"\n",
        "    for name2, code2 in list_names_codes:\n",
        "        score = fuzz.ratio(name, name2)\n",
        "        if (score > min_score) & (score > max_score) & (code == code2):\n",
        "            max_name = name2\n",
        "            max_score = score\n",
        "            max_code = code2\n",
        "    row['match_name'] = max_name\n",
        "    row['score'] = max_score\n",
        "    row['match_code'] = max_code\n",
        "    row['Ud pob'] = max_name\n",
        "    row['COD_INE'] = max_code\n",
        "    return row\n",
        "\n",
        "faltan_copy = faltan.copy()\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "faltan_copy = faltan_copy.progress_apply(lambda row: match_name(row, datos_ine_list, 50), axis=1)\n",
        "\n",
        "print(faltan_copy)\n",
        "\n",
        "faltan_copy.to_excel('ruta_1/CP_INE/faltan_restantes.xlsx')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
